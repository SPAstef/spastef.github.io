---
title: "From Zero Knowledge to Crypto Hero: 1/O(n)"
date: 2024-07-04
layout: post
---

When approached in a formal way, cryptography, particularly modern one, should be considered as 
a branch of [information theory](https://en.wikipedia.org/wiki/Information_theory), more than 
algebra or complexity theory. 
Sure, having well-founded tools that help us make sense of what we build is essential, but in 
principle not necessary. 

Consider the concept of *encryption*, intended as the process of manipulating a 
*plaintext message* $\bm{m}$, producing a *ciphertext message* $\bm{c}$, in such a way that deducing 
any property of $\bm{m}$ from $\bm{c}$ is impossible[^1], unless a certain *secret key* $\bm{k}$ is known: 
in general, $\bm{m}$, $\bm{c}$ and $\bm{k}$ could be anything, and the encryption procedure, let's 
call it $E$, can also be quite general: indeed, $E$ could be a randomized process which might not 
even always produce correct results, or even terminate for some combinations of plaintext and secret key! 
It is a bit limiting to already start posing limits, at the most general level possible, on the 
ways such things may work.

### Symbols, Alphabets, Strings
A first "restriction" (which really isn't one) we can make about our messages, keys, and other kinds 
of information that we are willing to process, is that they can be represented as 
*finite concatenations of symbols*, a.k.a. *strings*, where the symbols belong to a certain 
*alphabet* $\mathcal{A}$.
A trivial example would be the Latin (or English) alphabet:

$$\mathcal{A} = \set{\hex{a}, \hex{b}, \hex{c}, \dots, \hex{x}, \hex{y}, \hex{z}}$$

Obviously enough, the word $\hex{dog}$ is a string over the Latin alphabet.
Mathematically, we treat the alphabet as a set, so the number of symbols in the alphabet is simply 
its cardinality $\abs{\mathcal{A}}$ (for the Latin alphabet, $\abs{\mathcal{A}} = 26$). 
We also treat strings as tuples, hence we can equivalently represent the word 
$\hex{house}$ as $\tuple{\hex{h}, \hex{o}, \hex{u}, \hex{s}, \hex{e}}$, and the empty string is 
simply the empty tuple, which is also the empty set $\emptyset$.
A nice set operator that we will encounter often is [Kleene's closure](https://en.wikipedia.org/wiki/Kleene_star):

$$
\mathcal{A}^* = \bigcup_{n \in \mathbb{N}}{\mathcal{A}^n}
$$

where $\mathcal{A}^n = \underbrace{\mathcal{A} \times \cdots \times \mathcal{A}}_{n \text{ times}}$ 
denotes the n-fold [Cartesian product](https://en.wikipedia.org/wiki/Cartesian_product) of 
$\mathcal{A}$, with $\mathcal{A}^0 = \emptyset$ by convention.
For example:

$$
\set{\hex{0}, \hex{1}}^* = 
\set{\emptyset, \hex{0}, \hex{1}, \hex{00}, \hex{01}, \hex{10}, \hex{11}, \hex{000}, \dots, \hex{111}, \hex{0000}, \dots}
$$

This means that a string of symbols over $\mathcal{A}$ is nothing more than an element of $ \mathcal{A}^* $, neat!
Given two tuples $\bm{x}$ and $\bm{y}$, we denote with $\bm{x} \concat{} \bm{y}$ their *concatenation*, 
so for example $\hex{hot} \concat \hex{dog} = \hex{hotdog}$.


#### A Brief Digression on Terminology
Words have a meaning,  and in order to avoid confusion, we adopt the following convention for 
common terms:
- A *tuple* is a finite concatenation of arbitrary objects.
- A (finite) *string* is a tuple where all of its objects are symbols of an alphabet, that is: $S \in \mathcal{A}^*$.
- A (formal) *language* is a (potentially infinite) set of strings, usually defined via some property, that is $L \subseteq \mathcal{A}^*$.
- A (finite) *word* is a string that belongs to a *language*, hence a string $S$ can be a word w.r.t. some language $L$ but not w.r.t. some other language $L'$.
- A *sequence* is a (potentially infinite) ordered collection of symbols, usually numbers, defined via some formula (for example, "the sequence of all even numbers").



### "Wait, it's not just zeros and ones?" "Never has been..."
Although some famous general results in [computation theory](https://en.wikipedia.org/wiki/Linear_speedup_theorem),
allow us to basically treat everything as a "sequence of zeros and ones", and this is indeed what 
digital computers do (well, unless you go at the electronics level, where 
[zeros and ones are really just threshold measures](https://androidgrl.github.io/2019/01/01/binary/)), 
there are cases in which we need to treat this equivalence with care.

For example, suppose that we want to extract elements uniformly at random from some set $S$ (we 
denote this process with $x \getsrand{} S$), and that we have access to a 
[perfect coin flipper](https://en.wikipedia.org/wiki/Coin_flipping).
Clearly, sampling $x \getsrand \set{\hex{0}, \hex{1}}$ is trivial, as it corresponds to just tossing 
the coin (for example, we can agree that "heads" is $\hex{0}$ and "tails" is $\hex{1}$).
If we want to output a random binary string of a certain length $n$, then we just repeat the 
process $n$ times, and concatenating the bits obtained from each toss is going to result in an 
uniformly distributed string over $\set{\hex{0}, \hex{1}}^n$.

However, suppose that we want to use our perfect coin tosser to generate a random English letter:


Godspeed,

Stefano

<br>
<br>

[^1]: For the sake of simplicity, we say impossible: in the future, we will start using more appropriate terms of the technical jargon, such as *infeasible* or *negligible*. Similarly, the fact that "any property" of $M$ cannot be deduced from $C$ is also often a bit too strong.
